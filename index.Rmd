---
title: "HW 7"
author: "SDS322E"
date: "2021-10-14"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
---

```{r global_options, include=FALSE}
#DO NOT EDIT THIS CHUNK OR ANYTHING ABOVE IT!
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F, tidy=T, tidy.opts=list(width.cutoff=50), R.options=list(max.print=100,dplyr.print_max=100))
```

## Vaishnavi Sathiyamoorthy vs25229

**Please submit as a knitted HTML file on Canvas before the due date**

*For all questions, include the R commands/functions that you used to find your answer. Answers without supporting code will not receive credit.*

> **Review of how to submit this assignment**
> All homework assignments will be completed using R Markdown. These `.Rmd` files consist of text/syntax (formatted using Markdown) alongside embedded R code. 
> When you have completed the assignment (by adding R code inside codeblocks and supporting text outside of the codeblocks), create your document as follows:

> - Click the arrow next to the "Knit" button (above) 
> - Choose "Knit to HTML" and wait; fix any errors if applicable
> - Go to Files pane and put checkmark next to the correct HTML file
> - Click on the blue gear icon ("More") and click Export
> - Download the file and then upload to Canvas

---

#### WARNING: In this assignment, you will be performing computationally expensive operations on large datasets. If the server gets slow, try it on a different one:

- educcomp01.ccbb.utexas.edu
- educcomp02.ccbb.utexas.edu
- educcomp04.ccbb.utexas.edu

#### You are advised to begin working on this well before the due date. IF YOUR COMPUTER/SERVER IS RUNNING SLOWLY when trying to figure out the reshape, YOU ARE STRONGLY ENCOURAGED to take a subset of the wide merged data (e.g., first 500 rows) and test your code on that. Once you get everything working, replace your test sample with the entire dataset and run it one final time (it will likely take several minutes to knit the entire assignment: I would allow a half an hour just in case).

#### You will first need to read in the two files `background.csv` and `records.csv` (see code chunk below)

#### In these two datasets, your are given two simulated yet authentic institutional datasets.  The `background` dataset contains an ID column that identifies each unique student ($\approx 150,000$ from 2000 to 2018), along with background/demographic variables about each student (the data is fake, but the variables and many features of the data are true-to-life). `fseut` is the first semester a student enrolled at UT; `derivation` is based on a university race/ethnicity/nationality category; `SES` is a measure of socioeconomic status based on educational attainment and family income, averaged for both parents (1=lowest SES category, 10=highest SES category). `AP` and `CBE` indicate transfer credits from those exams. `SAT` is an SAT-equivalent score (ACT converted if applicable).

#### The `records` dataset is a wide file that contains, for each of eight possible years, a unique students' credit hours undertaken, hours passed, hours failed, grade points, and gpa. It would be wise to familiarize yourself with what these two datasets look like before diving into the assignment, especially `records` (i.e., you will save yourself a lot of time if you understand the organization).

### 1 (4 pts) 

#### How many IDs are in `background` that do not appear in `records`? How many IDs are in `records` that do not appear in `background`? How many IDs do the two datasets have in common? If there were supposed to be 150000 students total, how many students are missing entirely from these data (i.e., their IDs appear neither in the background data or student records)?

```{R}
library(tidyverse)

bg <- read_csv("/stor/work/SDS322ENW/background.csv")
rec <- read_csv("/stor/work/SDS322ENW/records.csv")

anti_join(bg, rec, by = c("ID" = "id")) %>% count()
anti_join(rec, bg, by = c("id" = "ID")) %>% count()
semi_join(rec, bg, by = c("id" = "ID")) %>% count()
150000 - ((anti_join(bg, rec, by = c("ID" = "id")) %>% count()) + (anti_join(rec, bg, by = c("id" = "ID")) %>% count()) + (semi_join(rec, bg, by = c("id" = "ID")) %>% count()))
```

*There are 1471 IDs that appear in background that do not appear in records. There are 2971 IDs that appear in records and not in background. There are 145529 IDs that both datasets have in common. 29 of the IDs appear in neither of the datasets.*

### 2.1 (1 pt) 

#### Perform a full-join on this data and save it as `fulldata`

```{R}
fulldata <- full_join(rec, bg, by = c("id" = "ID"))
```

### 2.2 (8 pt) 

#### Now, tidy this data. Create a new dataset (call it `longdat`). Each student-year-semester is an observation, so I want a column for year order (called `order`: first, second, third, etc.; need to use `separate` function), a column for `semester` (recoded with semester names rather than numbers: "9"="fall", "6"="summer", "2"="spring"; need to use separate), a column called `ccyys` (e.g., 20089, 20092, etc; you will need to create this variable name because it will be NA after separating), and columns for hrs.undertaken, hrs.fail, hrs.pass, grade.points, and gpa. There should be 17 columns total: `ID, fseut, derivation, female, SES, SAT, AP, CBE, graduated, order, semester, ccyys, hrs.undertaken, hrs.fail, hrs.pass, grade.points, gpa`. You will need to use pivot_longer(), separate(), and probably also pivot_wider(). DO NOT PRINT YOUR FINAL OUTPUT: instead, pipe it into `glimpse()`.


```{R}
## you might consider getting your code running with just the first 500 rows of your merged dataset to get things working (and then replace it with the full dataset at the end before knitting)
longdat <- fulldata %>% pivot_longer(2:145, names_to = "all_data", values_to = "all_values")
longdat<- longdat %>% separate(all_data, into = c("order", "semester", "type"), sep = "_") %>% pivot_wider(names_from = type, values_from = all_values)
longdat <- longdat %>% rename("ccyys" = "NA")
longdat <- longdat %>% mutate(semester = recode(semester, "2" = "Spring", "6" = "Summer", "9" = "Fall"))
longdat %>% glimpse()
```


### 3.1 (1 pt) 

#### Take the resulting tidy dataset and remove all rows containing NAs (**use this na-free dataset from here on unless otherwise noted**). How many rows were lost?

```{R}
na_omit_longdat <- longdat %>% na.omit
nrow(longdat) - nrow(na_omit_longdat)
```

*2,094,962 rows were lost.*


### 3.2 (1 pt) 

#### Notice there is no single variable that uniquely identifies a row. Use `unite(...,remove=F)` to add a new variable `unique` that combines `ccyys` and `ID` into a unique identifier. Show that it is in fact unique (i.e., that there are no duplicates in this column).

```{R}
na_omit_longdat <- na_omit_longdat %>% unite(ccyys, id, col="unique", sep="", remove = F)
```

###  3.3 (1 pt) 

#### Create a new variable called `year` by copying `ccyys` and then removing the fifth digit using `separate()`, or just by using `separate(..., remove=F)` without explicitly copying `ccyys`. The goal is 2008 instead of 20089, 2009 instead of 20092, etc. Keep the last number (9, 2, or 6) around in a column caled semester2 (this variable will make your life easier shortly). Pipe your output into `select(ID,ccyys,year,semester,semester2,ccyys) %>% glimpse()`

```{R}
na_omit_longdat <- na_omit_longdat %>% separate(unique, into = c("year_semester", "ID"), sep = 5, remove = F)
na_omit_longdat <- na_omit_longdat %>% separate(year_semester, into = c("year", "semester2"), sep = 4)
na_omit_longdat <- na_omit_longdat %>% select(-ID)
na_omit_longdat %>% select(id,ccyys,year,semester,semester2) %>% glimpse()
```

###  3.4 (2 pts) 

#### Again, after removing the NAs, create a new column with each student's *cumulative GPA* (call it `cum_gpa`) as of each semester (make sure data is sorted correctly before calculating cumulative statistics). Note that this is not as a simple as computing a running average of GPAs from each semester (think about an average of averages versus a weighted average). I would probably save this as something else rather than overwriting in case anything goes wrong. Pipe your output into `select(ID,ccyys,gpa,cum_gpa) %>% arrange(ID) %>% glimpse()`

```{R}
na_omit_longdat <- na_omit_longdat %>% group_by(id) %>% mutate(cum_gpa = (cumsum(grade.points)/cumsum(hrs.undertaken)))
na_omit_longdat %>% select(id,ccyys,gpa,cum_gpa) %>% arrange(id) %>% glimpse()
```

### 3.5 (1 pt) 

#### What proportion of students took at least one summer class? You are advised to use `semester2` rather than `semester` to summarize etc. (it takes much less time).

```{R}
(na_omit_longdat %>% filter(semester2 == 6) %>% select(id) %>% n_distinct) / (na_omit_longdat %>% select(id) %>% n_distinct)
```

*55.82% of students took at least one summer class.*

### 3.6 (1 pt) 

#### What is the record/maximum for number of semesters attended without graduating? Which student ID has this distinction?

```{R}
na_omit_longdat %>% filter(graduated == 0) %>% group_by(id) %>% summarise(num_sem = n_distinct(unique)) %>% slice_max(num_sem)
```

*The maximum number of semesters without graduating is 21 and the student ID is 13501.*

```{R, echo=F}
## DO NOT DELETE THIS BLOCK!
sessionInfo()
Sys.time()
Sys.info()
```